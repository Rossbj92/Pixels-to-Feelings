{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(sys.path[0].replace('notebooks', 'src'))\n",
    "\n",
    "import modeling.modeling_utils as m\n",
    "from modeling.unbiasedemo_utils import make_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.6.0'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.torch.cuda.is_available() # Check for GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "device = m.torch.device(\"cuda\" if m.torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "m.torch.backends.cudnn.benchmark=True # Helps optimize training w/ GPU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "This notebook tests 3 models on the ```UnBiasedEmo``` dataset. This dataset was specifically built to evaluate visual sentiment models, using the same objects/scenes (e.g., athletes, dogs) across different emotions (e.g., anger, joy). Instructions for downloading the dataset can be found here: https://rpand002.github.io/emotion.html. After downloading, unzip into the ```data``` directory.\n",
    "<br>\n",
    "\n",
    "The 3 models tested are:\n",
    "1. The curriculum-based webemo_\n",
    "2. The Deep Emotion fine-tuned Resnet50\n",
    "3. A Resnet50 trained on ImageNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "# Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "deepemo_df = make_df('../data/Flickr')\n",
    "deepemo_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "Following the instructions above should give you a dataframe in this format:\n",
    "```\n",
    "                file    | labels\n",
    "817 | joy/family/354.jpg | 4\n",
    "1301 | love/cat/185.jpg | 2\n",
    "1737 | love/scenery/176.jpg | 2\n",
    "2783 | surprise/people/12 6.jpg | 0\n",
    "435 | anger/tiger/68.jpg | 3\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "Next, I split the data into train/validation/test sets and utilize the dataset/dataloader classes for multiprocessing during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "train, test = m.train_val_split(unbiasedemo_df['file'], unbiasedemo_df['labels'], \n",
    "                                    test_size = 0.2, random_state=713)\n",
    "train_split, val_split = train_val_split(train_df['file'], train_df['labels'], test_size = 0.1, random_state=611)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "train_transforms = m.transforms.Compose([m.transforms.Resize(256),\n",
    "                                         m.transforms.RandomCrop(224),\n",
    "                                         m.transforms.ToTensor(),\n",
    "                                         m.transforms.Normalize(mean=[0.485, 0.456, 0.406], #OG means/sds from imagenet\n",
    "                                                                std=[0.229, 0.224, 0.225])\n",
    "                                        ])\n",
    "val_transforms = m.transforms.Compose([m.transforms.Resize(256),\n",
    "                                       m.transforms.CenterCrop(224),\n",
    "                                       m.transforms.ToTensor(),\n",
    "                                       m.transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                                              std=[0.229, 0.224, 0.225])\n",
    "                                      ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "train_dataset = m.ImgDataset(df=train_split,\n",
    "                                root_dir='../data/UnBiasedEmo/images',\n",
    "                                percent_sample=1,\n",
    "                                transform=train_transforms)\n",
    "val_dataset = m.ImgDataset(df=val_split,\n",
    "                              root_dir='../data/UnBiasedEmo/images',\n",
    "                              percent_sample=1,\n",
    "                              transform=val_transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "samples_weights = m.weighted_sample(train_split, 'labels')\n",
    "weighted_sampler = m.WeightedRandomSampler(weights=samples_weights, num_samples=len(samples_weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "loaders = {'train': m.DataLoader(train_dataset,\n",
    "                               batch_size=128, \n",
    "                               sampler=weighted_sampler,\n",
    "                               #pin_memory=True, # Only use pin_memory with GPU\n",
    "                               num_workers=4), \n",
    "              'val': m.DataLoader(val_dataset, \n",
    "                             batch_size=128,\n",
    "                             #pin_memory=True,\n",
    "                             num_workers=4)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "# Training Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "### WEBEmo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "webemo_model = m.load_model(path='../models/l3model.tar', \n",
    "                        base=m.models.resnet50(pretrained=False), \n",
    "                        old_classes=25, \n",
    "                        new_classes=25, \n",
    "                        device=device)\n",
    "# Freeze layers for feature extraction\n",
    "for param in webemo_model.parameters():\n",
    "    param.requires_grad = False\n",
    "    \n",
    "webemo_model.fc = m.nn.Sequential(nn.Linear(num_ftrs, 6))\n",
    "webemo_model = webemo_model.to(device)\n",
    "webemo_criterion = m.nn.CrossEntropyLoss().to(device)\n",
    "webemo_optimizer = m.torch.optim.SGD(webemo_model.parameters(), \n",
    "                                  lr=0.001, \n",
    "                                  momentum=0.9, \n",
    "                                  weight_decay=0.0001)\n",
    "webemo_scheduler = m.lr_scheduler.ReduceLROnPlateau(webemo_optimizer, patience=5, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "webemo_train = m.train_model(model=webemo_model, \n",
    "                             dataloader=loaders, \n",
    "                             criterion= webemo_criterion, \n",
    "                             optimizer= webemo_optim,\n",
    "                             save_path='../models/webemo_exp.tar',\n",
    "                             num_epochs=50,\n",
    "                             scheduler= webemo_scheduler,\n",
    "                             early_stopping=m.EarlyStopping(patience=10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "### Deep Emotion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "webemo_model = m.load_model(path='../models/deepemo_model.tar', \n",
    "                        base=m.models.resnet50(pretrained=False), \n",
    "                        old_classes=8, \n",
    "                        new_classes=8, \n",
    "                        device=device)\n",
    "\n",
    "for param in deepemo_model.parameters():\n",
    "    param.requires_grad = False\n",
    "    \n",
    "deepemo_model.fc = m.nn.Sequential(nn.Linear(2048, 6))\n",
    "deepemo_model = deepemo_model.to(device)\n",
    "deepemo_criterion = m.nn.CrossEntropyLoss().to(device)\n",
    "deepemo_optimizer = m.torch.optim.SGD(deepemo_model.parameters(), \n",
    "                                  lr=0.001, \n",
    "                                  momentum=0.9, \n",
    "                                  weight_decay=0.0001)\n",
    "deepemo_scheduler = m.lr_scheduler.ReduceLROnPlateau(deepemo_optimizer, patience=5, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "deepemo_train = m.train_model(model=deepemo_model, \n",
    "                             dataloader=loaders, \n",
    "                             criterion= deepemo_criterion, \n",
    "                             optimizer= deepemo_optim,\n",
    "                             save_path='../models/deepemo_exp.tar',\n",
    "                             num_epochs=50,\n",
    "                             scheduler= deepemo_scheduler,\n",
    "                             early_stopping=m.EarlyStopping(patience=10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "### ImageNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "imagenet_model = models.resnet50(pretrained=True)\n",
    "\n",
    "for param in imagenet_model.parameters():\n",
    "    param.requires_grad = False\n",
    "    \n",
    "imagenet_model.fc = m.nn.Sequential(nn.Linear(2048, 6))\n",
    "imagenet_model = imagenet_model.to(device)\n",
    "imagenet_criterion = m.nn.CrossEntropyLoss().to(device)\n",
    "imagenet_optimizer = m.torch.optim.SGD(imagenet_model.parameters(), \n",
    "                                  lr=0.001, \n",
    "                                  momentum=0.9, \n",
    "                                  weight_decay=0.0001)\n",
    "imagenet_scheduler = m.lr_scheduler.ReduceLROnPlateau(imagenet_optimizer, patience=5, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "imagenet_train = m.train_model(model=imagenet_model, \n",
    "                             dataloader=loaders, \n",
    "                             criterion= imagenet_criterion, \n",
    "                             optimizer= imagenet_optim,\n",
    "                             save_path='../models/imagenet_exp.tar',\n",
    "                             num_epochs=50,\n",
    "                             scheduler= imagenet_scheduler,\n",
    "                             early_stopping=m.EarlyStopping(patience=10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "# Testing Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "test_dataset = ImgDataset(df=test,\n",
    "                           root_dir='../data/UnBiasedEmo/images',\n",
    "                           percent_sample=1,\n",
    "                           transform=val_transforms)\n",
    "test_loader = DataLoader(test_dataset, \n",
    "                        batch_size=128,\n",
    "                        #pin_memory=True,\n",
    "                        num_workers=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "### WEBEmo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "test_webemo_model = m.load_model(path='../models/webemo_exp.tar', \n",
    "                          base=m.models.resnet50(pretrained=False), \n",
    "                          old_classes=8, \n",
    "                          new_classes=8, \n",
    "                          device=device)\n",
    "test_webemo_model = test_webemo_model.eval()\n",
    "test_webemo_model = test_webemo_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "m.evaluate_model(test_webemo_model, test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "```\n",
    "tensor(0.7274, device='cuda:0', dtype=torch.float64)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "### Deep Emotion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "test_deepemo_model = m.load_model(path='../models/deepemo_exp.tar', \n",
    "                          base=m.models.resnet50(pretrained=False), \n",
    "                          old_classes=8, \n",
    "                          new_classes=8, \n",
    "                          device=device)\n",
    "test_deepemo_model = test_deepemo_model.eval()\n",
    "test_deepemo_model = test_deepemo_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "m.evaluate_model(test_deepemo_model, test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "```\n",
    "tensor(0.6585, device='cuda:0', dtype=torch.float64)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "### ImageNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "test_imagenet_model = m.load_model(path='../models/imagenet_exp.tar', \n",
    "                          base=m.models.resnet50(pretrained=False), \n",
    "                          old_classes=8, \n",
    "                          new_classes=8, \n",
    "                          device=device)\n",
    "test_imagenet_model = test_imagenet_model.eval()\n",
    "test_imagenet_model = test_imagenet_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "m.evaluate_model(test_imagenet_model, test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "```\n",
    "tensor(0.5928, device='cuda:0', dtype=torch.float64)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
