{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(sys.path[0].replace('notebooks', 'src'))\n",
    "\n",
    "import modeling.modeling_utils as m\n",
    "from modeling.deepemo_utils import make_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.6.0'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.torch.cuda.is_available() # Check for GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "device = m.torch.device(\"cuda\" if m.torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "m.torch.backends.cudnn.benchmark=True # Helps optimize training w/ GPU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "This notebook contains the code used to fine-tune a ```Resnet50``` model on the ```Deep Emotion``` dataset. In the context of this project, this model is tested against the curriculum-based ```WEBEmo``` trained model in the ```experiment``` notebook.\n",
    "\n",
    "The ```Deep Emotion``` dataset can be downloaded here: https://www.cs.rochester.edu/u/qyou/deepemotion/. After downloading, unzip into the ```data``` directory."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "deepemo_df = make_df('../data/Flickr')\n",
    "deepemo_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "You should obtain a dataframe in this format:\n",
    "```\n",
    "file | labels\n",
    "0 | excitement/excitement_1556.jpg | 3\n",
    "1 | excitement/excitement_0890.jpg | 3\n",
    "2 | excitement/excitement_0648.jpg | 3\n",
    "3 | excitement/excitement_1230.jpg | 3\n",
    "4 | excitement/excitement_2739.jpg | 3\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "Following that, the data are ready to be put into a Pytorch-friendly format and trained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# Separating into train, validation, and test splits\n",
    "train, test = m.train_val_split(X=deepemo_df['file'], \n",
    "                                y=deepemo_df['labels'], \n",
    "                                test_size=0.2, \n",
    "                                random_state=713)\n",
    "train_split, val_split = m.train_val_split(X=train_df['file'], \n",
    "                                           y=train_df['labels'], \n",
    "                                           test_size = 0.1, \n",
    "                                           random_state=611)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "train_transforms = m.transforms.Compose([m.transforms.Resize(256),\n",
    "                                         m.transforms.RandomCrop(224),\n",
    "                                         m.transforms.ToTensor(),\n",
    "                                         m.transforms.Normalize(mean=[0.485, 0.456, 0.406], #OG means/sds from imagenet\n",
    "                                                                std=[0.229, 0.224, 0.225])\n",
    "                                        ])\n",
    "val_transforms = m.transforms.Compose([m.transforms.Resize(256),\n",
    "                                       m.transforms.CenterCrop(224),\n",
    "                                       m.transforms.ToTensor(),\n",
    "                                       m.transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                                              std=[0.229, 0.224, 0.225])\n",
    "                                      ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "train_dataset = m.ImgDataset(df=train_split,\n",
    "                             root_dir='../data/Flickr',\n",
    "                             percent_sample=1,\n",
    "                             transform=train_transforms)\n",
    "val_dataset = m.ImgDataset(df=val_split,\n",
    "                           root_dir='../data/Flickr',\n",
    "                           percent_sample=1,\n",
    "                           transform=val_transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "samples_weights = m.weighted_sample(train_split, 'labels')\n",
    "weighted_sampler = m.WeightedRandomSampler(weights=samples_weights, num_samples=len(samples_weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# Pytorch DataLoader iteratively loads minibatches during training\n",
    "loaders = {'train': m.DataLoader(train_dataset,\n",
    "                                 batch_size=128, \n",
    "                                 sampler=weighted_sampler,\n",
    "                                 #pin_memory=True, # Only use pin_memory with GPU\n",
    "                                 num_workers=4), \n",
    "           'val': m.DataLoader(val_dataset, \n",
    "                               batch_size=128,\n",
    "                               #pin_memory=True,\n",
    "                               num_workers=4)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "# Train Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "Similar to the level-1 ```WEBEmo``` model, a pre-trained ```Resnet50``` is fine-tuned on the ```Deep Emotion``` dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "model = m.models.resnet50(pretrained=True)\n",
    "num_ftrs = model.fc.in_features\n",
    "model.fc = m.nn.Linear(num_ftrs, 8) # 8 possible emotions\n",
    "model = model.to(device)\n",
    "criterion = m.nn.CrossEntropyLoss().to(device)\n",
    "optim = m.torch.optim.SGD(model.parameters(), \n",
    "                          lr=0.001, \n",
    "                          momentum=0.9, \n",
    "                          weight_decay=0.0001)\n",
    "scheduler = m.lr_scheduler.ReduceLROnPlateau(optim, patience=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# Train\n",
    "model_train = m.train_model(model=model, \n",
    "                            dataloader=loaders_dict, \n",
    "                            criterion= criterion, \n",
    "                            optimizer= optim,\n",
    "                            save_path='../models/deepemo_model.tar',\n",
    "                            num_epochs=50,\n",
    "                            scheduler= scheduler,\n",
    "                            early_stopping=m.EarlyStopping(patience=10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "# Evaluate on Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "test_dataset = m.ImgDataset(df=test,\n",
    "                            root_dir='../data/Flickr',\n",
    "                            percent_sample=1,\n",
    "                            transform=val_transforms)\n",
    "test_loader = m.DataLoader(test_dataset, \n",
    "                           batch_size=128,\n",
    "                           #pin_memory=True,\n",
    "                           num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "test_model = m.load_model(path='../models/deepemo_model.tar', \n",
    "                          base=m.models.resnet50(pretrained=False), \n",
    "                          old_classes=8, \n",
    "                          new_classes=8, \n",
    "                          device=device)\n",
    "test_model = test_model.eval()\n",
    "test_model = test_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "m.evaluate_model(test_model, test_loader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
